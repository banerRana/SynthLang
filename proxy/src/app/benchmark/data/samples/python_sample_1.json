{
  "text": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n\n# Load the dataset\n#load_data\ndf = pd.read_csv('customer_data.csv')\n\n# Exploratory Data Analysis\n#analyze_data\nprint(f\"Dataset shape: {df.shape}\")\nprint(df.info())\nprint(df.describe())\n\n# Check for missing values\n#check_missing\nmissing_values = df.isnull().sum()\nprint(f\"Missing values per column:\\n{missing_values}\")\n\n# Data Visualization\n#visualize_data\nplt.figure(figsize=(12, 8))\nsns.heatmap(df.corr(), annot=True, cmap='coolwarm')\nplt.title('Correlation Matrix')\nplt.savefig('correlation_matrix.png')\n\n# Feature Engineering\n#engineer_features\n# Create new features\ndf['purchase_frequency'] = df['total_purchases'] / df['customer_tenure_days']\ndf['average_order_value'] = df['total_spend'] / df['total_purchases']\ndf['days_since_last_purchase'] = pd.to_datetime('today') - pd.to_datetime(df['last_purchase_date'])\ndf['days_since_last_purchase'] = df['days_since_last_purchase'].dt.days\n\n# Encode categorical variables\ndf = pd.get_dummies(df, columns=['customer_segment', 'preferred_channel'])\n\n# Prepare data for modeling\n#prepare_model_data\nX = df.drop(['customer_id', 'churn_status', 'last_purchase_date'], axis=1)\ny = df['churn_status']\n\n# Split the data\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n\n# Scale the features\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# Train a model\n#train_model\nmodel = RandomForestClassifier(n_estimators=100, random_state=42)\nmodel.fit(X_train_scaled, y_train)\n\n# Evaluate the model\n#evaluate_model\ny_pred = model.predict(X_test_scaled)\naccuracy = accuracy_score(y_test, y_pred)\nprint(f\"Model Accuracy: {accuracy:.4f}\")\nprint(\"\\nClassification Report:\")\nprint(classification_report(y_test, y_pred))\n\n# Feature importance\n#analyze_importance\nfeature_importance = pd.DataFrame({\n    'Feature': X.columns,\n    'Importance': model.feature_importances_\n}).sort_values('Importance', ascending=False)\n\nplt.figure(figsize=(10, 6))\nsns.barplot(x='Importance', y='Feature', data=feature_importance.head(10))\nplt.title('Top 10 Feature Importance')\nplt.tight_layout()\nplt.savefig('feature_importance.png')\n\n# Save the model\n#save_model\nimport joblib\njoblib.dump(model, 'churn_prediction_model.pkl')\njoblib.dump(scaler, 'feature_scaler.pkl')\n\nprint(\"Model training and evaluation complete!\")",
  "metadata": {
    "language": "python",
    "heading": "Code Examples for Benchmarking",
    "length": 2669,
    "id": "python_1",
    "description": "python code example: Code Examples for Benchmarking"
  }
}