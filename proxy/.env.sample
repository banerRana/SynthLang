# SynthLang Proxy Configuration
# Copy this file to .env and modify as needed

# Server Configuration
PORT=8000
HOST=0.0.0.0
DEBUG=false

# Security
# Generate a secure random key for encryption (32 bytes, base64 encoded)
# You can generate one with: python -c "import os, base64; print(base64.b64encode(os.urandom(32)).decode())"
ENCRYPTION_KEY=

# Database Configuration
# PostgreSQL
DB_USER=postgres
DB_PASSWORD=postgres
DB_HOST=localhost
DB_PORT=5432
DB_NAME=synthlang_proxy

# For development/testing, you can use SQLite instead
USE_SQLITE=0
SQLITE_PATH=sqlite+aiosqlite:///./synthlang_proxy.db

# Debug SQL queries (set to 1 to enable)
DEBUG_SQL=0

# Rate Limiting
# Default rate limits (requests per minute)
DEFAULT_RATE_LIMIT=60
PREMIUM_RATE_LIMIT=120

# SynthLang Integration
# Path to SynthLang CLI executable
SYNTHLANG_PATH=synthlang
# Enable/disable SynthLang compression (set to 0 to disable)
ENABLE_SYNTHLANG=1

# LLM Provider Configuration
# OpenAI API key
OPENAI_API_KEY=
# Default model to use
DEFAULT_MODEL=gpt-4o
# Timeout for LLM API calls (in seconds)
LLM_TIMEOUT=30

# Semantic Cache
# Enable/disable semantic cache (set to 0 to disable)
ENABLE_CACHE=1
# Similarity threshold for cache hits (0.0-1.0)
CACHE_SIMILARITY_THRESHOLD=0.95
# Maximum number of items to keep in cache
CACHE_MAX_ITEMS=1000

# Logging
LOG_LEVEL=INFO
LOG_FILE=proxy.log