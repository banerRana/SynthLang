# SynthLang Proxy Configuration
# Copy this file to .env and modify as needed

# Server Configuration
PORT=8000
HOST=0.0.0.0
DEBUG=false

# Security
# Generate a secure random key for encryption (32 bytes, base64 encoded)
# You can generate one with: python -c "import os, base64; print(base64.b64encode(os.urandom(32)).decode())"
ENCRYPTION_KEY=

# Database Configuration
# PostgreSQL connection URL (required)
DATABASE_URL=postgresql+asyncpg://postgres:postgres@localhost:5432/synthlang_proxy

# For development/testing, you can use SQLite instead
USE_SQLITE=0
SQLITE_PATH=sqlite+aiosqlite:///./synthlang_proxy.db

# Debug SQL queries (set to 1 to enable)
DEBUG_SQL=0

# Rate Limiting
# Default rate limits (requests per minute)
DEFAULT_RATE_LIMIT_QPM=60
PREMIUM_RATE_LIMIT=120

# SynthLang Integration
# Enable/disable SynthLang compression (set to 0 to disable)
USE_SYNTHLANG=1

# PII Masking Configuration
# Mask PII before sending to LLM (set to 1 to enable)
MASK_PII_BEFORE_LLM=0
# Mask PII in logs and database (set to 0 to disable)
MASK_PII_IN_LOGS=1

# LLM Provider Configuration
# OpenAI API key (required)
OPENAI_API_KEY=
# Default model to use
DEFAULT_MODEL=gpt-4o
# Timeout for LLM API calls (in seconds)
LLM_TIMEOUT=30

# Semantic Cache
# Enable/disable semantic cache (set to 0 to disable)
ENABLE_CACHE=1
# Similarity threshold for cache hits (0.0-1.0)
CACHE_SIMILARITY_THRESHOLD=0.95
# Maximum number of items to keep in cache
CACHE_MAX_ITEMS=1000

# Logging
LOG_LEVEL=INFO
LOG_FILE=proxy.log